{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Raspberry Pi Cluster I have worked most of my professional life with systems built with Intel x86, x64 and ia64 chips. Intel processors use Complex Instruction Set Computing while Arm uses Reduced Instruction Set Computing. Processors with CISC architecture look to move complexity to hardware to simlify code, so small code sizes with high cycles per second. Processors with RISC architecture invert the relationship larger code size with low cycles per second. Anyone who has worked in a data center has an awareness of importance of the amount of heat generated by Intel powered servers. There isn\u2019t much heat generated from allowing electricity to flow through something (unless there is A LOT of electricity). All of Arm\u2019s designs are energy efficient which is why they have become popular for running in smartphones, tablets and other embedded devices. If Arm processors can get traction used in servers this can only be good news for data center electricity usage. I enjoy learning by doing and to begin to better understand Arm looked to build a cluster of Raspberry Pi. My goals of cluster include: Understanding more about Raspberry Pi hardware Understanding how an distributed application might work across physical hosts using MPI. MPI is a programming model that is widely used for parallel programming in a cluster. Understanding how micro-servies application may work in Edge locations running Kubernetes on low-cost hardware. Understanding how ESXi on Arm development is progressing","title":"Home"},{"location":"#raspberry-pi-cluster","text":"I have worked most of my professional life with systems built with Intel x86, x64 and ia64 chips. Intel processors use Complex Instruction Set Computing while Arm uses Reduced Instruction Set Computing. Processors with CISC architecture look to move complexity to hardware to simlify code, so small code sizes with high cycles per second. Processors with RISC architecture invert the relationship larger code size with low cycles per second. Anyone who has worked in a data center has an awareness of importance of the amount of heat generated by Intel powered servers. There isn\u2019t much heat generated from allowing electricity to flow through something (unless there is A LOT of electricity). All of Arm\u2019s designs are energy efficient which is why they have become popular for running in smartphones, tablets and other embedded devices. If Arm processors can get traction used in servers this can only be good news for data center electricity usage. I enjoy learning by doing and to begin to better understand Arm looked to build a cluster of Raspberry Pi. My goals of cluster include: Understanding more about Raspberry Pi hardware Understanding how an distributed application might work across physical hosts using MPI. MPI is a programming model that is widely used for parallel programming in a cluster. Understanding how micro-servies application may work in Edge locations running Kubernetes on low-cost hardware. Understanding how ESXi on Arm development is progressing","title":"Raspberry Pi Cluster"},{"location":"hardware/","text":"Pi Cluster Rack Hardware Power over Ethernet One of my goals for the cluster was the hardware self-contained and easy to connect to network and power. Out of the box the Raspberry Pi 4b is powered over USB-C and operates at 5.1V upto 3A so has maximum draw (5.1*3=) 15.3watt. While I could use one official Raspberry Pi USB-C 15.3watt power supply for each this would require four power sockets. A cleaner cabling solution is to equip each Pi 4b with a PoE HAT and power each using a Power over Ethernet\u2013enabled network. When the Pi is cabled to a PoE network switch port the power gets routed to four PoE pins on the Pi board. The PoE switch ports deliver between 27-57volts. The PoE HAT connects to the four PoE pins and has onboard transformer which converts input voltage to 5volt and then routes this to the GPIO power pins. Network Switch For selecting the PoE network switch there are two important factors I considered. PoE has two specifications the initial 802.3af (upto 15watt) and revised 802.3at (upto 30watt), the Pi 4b has 15.3watt maximum draw so ports supporting 802.3af. Another important factor to consider is maximum draw across all PoE ports here our maximum draw would be (15.3*4=) 61.2watts. The Netgear GS305P has five ports with four supported for 802.3af or 802.3at and is rated for 63W power draw, it is also compact with dimensions 158 x 101 x 29 mm. Storage For storage selection the SanDisk Extreme offers sequential read up to 160MB/sec and sequential write up to 90MB/sec. The SanDisk Ultra offers sequential read up to 100MB/sec and sequential write up to 90MB/sec. The Pi4B has a dedicated SD card socket which suports 1.8V, DDR50 mode (at a peak bandwidth of 50 Megabytes / sec). The Pi 4h as a USB 3 interface which has peak bandwidth 620 Megabytes / sec. The Arcanite 128GB USB 3.1 Flash Drive has a small formfactor and low cost and offers read speeds up to 400 MB/s and write speeds up to 100 MB/s. Mounting Rack Towards goal of keeping cluster self contained I wanted to house the network switch and four Pi 4b in a rack. There are vaious off the shelf options for stacking Pi's but I couldn't find a great solution for my specific requirement. I'd not done a project using custom cut metal before and thought this would be a good opportunity to explore. I thought aluminium would be good to polish to a nice finish so I decided to use 3mm medium strength 5251 aluminium. I found a UK based mail-order laser cutting provider Lasered . To make the order required drawing in either Drawing Interchange Format (DXF), AutoCAD (DWG) of Mastercam Numerical Control File (NC) format to create this I used open-source LibreCAD software. I'd not used CAD software before so there was a learning curve but this was not large and within few hours I'd created two drawings. The cluster will primarily be used as Kubernetes cluster so I designed all the plates shaped as heptagons, the top and base plates also have Raspberry Pi logo. For attaching plates together allowing enough space for airflow I chose 35mm standoffs with M4 thread to accept M4 I gave holes a 4.2mm radius. For mounting the Pi the board has 2.7mm holes to accept M2.5 thread screws so I mirror these on the plate with 2.7mm radius and use 5mm standoff to lift slightly. I added a rectangular hole behin Pi on each shelf to allow for internal PoE cable routing. The rack dimensions when assembled, widest points the heptagon is 210mm and (6x3mm=)18mm plates plus (5x40mm)=200 standoffs gives total height of 218mm. I got the plates cut and they looked better than expected except the standoff holes looked rather large. I checked the the calipers and noticed my planned 4.2mm holes were 8.4mm and my 2.7mm holes 5.4mm. Seems I had entered diameter as value for circle radius parameter. Luckily I hadn't ordered the standoffs, nuts or bolts. It was easy to switched from M4 to M6 for the between layer standoffs but as the Pi board only accepts M2.5 I kept these and added a washer to prevent bolt going straight through the mount hole on the shelf. Rack Cabling To keep the internal rack cabling tidy I decided to create each cable with custom length. The PoE standards require category 3 cable or better for 802.3af (upto 15watt) and category 5 cable for better for 802.3at (upto 30watt). The Raspberry Pi NIC can operate at 1Gb/s, category 5 is cable rated for 100Mb/s, category 5e is cable rated for 1Gb/s, category 6 is cable rated for 10Gb/s. To operate the Pi's over PoE at full potential I use category 5e cable and crimped RJ45 connectors. Finished Rack Hardware Bill of materials 35mm M6 Standoffs (Bag 50) \u00a330 10mm M6 screws (Bag 100) \u00a36.45 M6 hexagonal nuts (Bag 250) \u00a36 5mm M2.5 Standoffs (Bag 20) \u00a35 6mm M2.5 screws (Bag 100) \u00a33.50 Custom laser cut aluminium plates \u00a360 <1m Cat5e cable RJ45 cable crimping tool kit \u00a320 Total rack parts cost ~\u00a3130 4x Raspberry Pi 4B WITH 8GB RAM (4X \u00a373.50=) \u00a3294 4x Raspberry Pi PoE HAT (4x \u00a318=) \u00a372 4x 128GB SanDisk Extreme (4x \u00a324=) \u00a396 4x Arcanite 128GB USB 3.1 Flash Drive (4x \u00a320=) \u00a380 Netgear GS305P \u00a345 Total cluster parts cost ~\u00a3717","title":"Hardware"},{"location":"hardware/#pi-cluster-rack-hardware","text":"","title":"Pi Cluster Rack Hardware"},{"location":"hardware/#power-over-ethernet","text":"One of my goals for the cluster was the hardware self-contained and easy to connect to network and power. Out of the box the Raspberry Pi 4b is powered over USB-C and operates at 5.1V upto 3A so has maximum draw (5.1*3=) 15.3watt. While I could use one official Raspberry Pi USB-C 15.3watt power supply for each this would require four power sockets. A cleaner cabling solution is to equip each Pi 4b with a PoE HAT and power each using a Power over Ethernet\u2013enabled network. When the Pi is cabled to a PoE network switch port the power gets routed to four PoE pins on the Pi board. The PoE switch ports deliver between 27-57volts. The PoE HAT connects to the four PoE pins and has onboard transformer which converts input voltage to 5volt and then routes this to the GPIO power pins.","title":"Power over Ethernet"},{"location":"hardware/#network-switch","text":"For selecting the PoE network switch there are two important factors I considered. PoE has two specifications the initial 802.3af (upto 15watt) and revised 802.3at (upto 30watt), the Pi 4b has 15.3watt maximum draw so ports supporting 802.3af. Another important factor to consider is maximum draw across all PoE ports here our maximum draw would be (15.3*4=) 61.2watts. The Netgear GS305P has five ports with four supported for 802.3af or 802.3at and is rated for 63W power draw, it is also compact with dimensions 158 x 101 x 29 mm.","title":"Network Switch"},{"location":"hardware/#storage","text":"For storage selection the SanDisk Extreme offers sequential read up to 160MB/sec and sequential write up to 90MB/sec. The SanDisk Ultra offers sequential read up to 100MB/sec and sequential write up to 90MB/sec. The Pi4B has a dedicated SD card socket which suports 1.8V, DDR50 mode (at a peak bandwidth of 50 Megabytes / sec). The Pi 4h as a USB 3 interface which has peak bandwidth 620 Megabytes / sec. The Arcanite 128GB USB 3.1 Flash Drive has a small formfactor and low cost and offers read speeds up to 400 MB/s and write speeds up to 100 MB/s.","title":"Storage"},{"location":"hardware/#mounting-rack","text":"Towards goal of keeping cluster self contained I wanted to house the network switch and four Pi 4b in a rack. There are vaious off the shelf options for stacking Pi's but I couldn't find a great solution for my specific requirement. I'd not done a project using custom cut metal before and thought this would be a good opportunity to explore. I thought aluminium would be good to polish to a nice finish so I decided to use 3mm medium strength 5251 aluminium. I found a UK based mail-order laser cutting provider Lasered . To make the order required drawing in either Drawing Interchange Format (DXF), AutoCAD (DWG) of Mastercam Numerical Control File (NC) format to create this I used open-source LibreCAD software. I'd not used CAD software before so there was a learning curve but this was not large and within few hours I'd created two drawings. The cluster will primarily be used as Kubernetes cluster so I designed all the plates shaped as heptagons, the top and base plates also have Raspberry Pi logo. For attaching plates together allowing enough space for airflow I chose 35mm standoffs with M4 thread to accept M4 I gave holes a 4.2mm radius. For mounting the Pi the board has 2.7mm holes to accept M2.5 thread screws so I mirror these on the plate with 2.7mm radius and use 5mm standoff to lift slightly. I added a rectangular hole behin Pi on each shelf to allow for internal PoE cable routing. The rack dimensions when assembled, widest points the heptagon is 210mm and (6x3mm=)18mm plates plus (5x40mm)=200 standoffs gives total height of 218mm. I got the plates cut and they looked better than expected except the standoff holes looked rather large. I checked the the calipers and noticed my planned 4.2mm holes were 8.4mm and my 2.7mm holes 5.4mm. Seems I had entered diameter as value for circle radius parameter. Luckily I hadn't ordered the standoffs, nuts or bolts. It was easy to switched from M4 to M6 for the between layer standoffs but as the Pi board only accepts M2.5 I kept these and added a washer to prevent bolt going straight through the mount hole on the shelf.","title":"Mounting Rack"},{"location":"hardware/#rack-cabling","text":"To keep the internal rack cabling tidy I decided to create each cable with custom length. The PoE standards require category 3 cable or better for 802.3af (upto 15watt) and category 5 cable for better for 802.3at (upto 30watt). The Raspberry Pi NIC can operate at 1Gb/s, category 5 is cable rated for 100Mb/s, category 5e is cable rated for 1Gb/s, category 6 is cable rated for 10Gb/s. To operate the Pi's over PoE at full potential I use category 5e cable and crimped RJ45 connectors.","title":"Rack Cabling"},{"location":"hardware/#finished-rack","text":"","title":"Finished Rack"},{"location":"hardware/#hardware-bill-of-materials","text":"35mm M6 Standoffs (Bag 50) \u00a330 10mm M6 screws (Bag 100) \u00a36.45 M6 hexagonal nuts (Bag 250) \u00a36 5mm M2.5 Standoffs (Bag 20) \u00a35 6mm M2.5 screws (Bag 100) \u00a33.50 Custom laser cut aluminium plates \u00a360 <1m Cat5e cable RJ45 cable crimping tool kit \u00a320 Total rack parts cost ~\u00a3130 4x Raspberry Pi 4B WITH 8GB RAM (4X \u00a373.50=) \u00a3294 4x Raspberry Pi PoE HAT (4x \u00a318=) \u00a372 4x 128GB SanDisk Extreme (4x \u00a324=) \u00a396 4x Arcanite 128GB USB 3.1 Flash Drive (4x \u00a320=) \u00a380 Netgear GS305P \u00a345 Total cluster parts cost ~\u00a3717","title":"Hardware Bill of materials"},{"location":"mpi/","text":"Parrallel Programming Each Raspberry Pi is a small unit of compute, one of my goals is to understand how operating many in a cluster. There are various approaches to parallel computational models, message-passing has proven to be an effective one. MPI the Message Passing Interface, is a standardized and portable message-passing system designed to function on a wide variety of parallel computers. My prefered language is Python and usefully there is MPI for Python . sudo apt-get install -y libopenmpi-dev python-dev pip sudo pip install mpi4py mpirun --version All the RPIs in the cluster will access each other via SSH, this communication needs to be passwordless. The first thing you need to do is generate an SSH key pair on first host. ssh-keygen -t rsa -b 4096 Once key generated to enable passwordless access, upload a copy of the public key to the other three servers. ssh-copy-id ubuntu@[server_ip_address] Repeat keygen and copy public key process on all four hosts. In order for mpi to distribute workload the node where execution occurs needs to understand which nodes are available. The machinename parameter can be used to point to a text file containing list of nodes. In order name we can use names we can add entries to hosts file. sudo sh -c 'echo \"192.168.1.100 rpi-0\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.101 rpi-1\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.102 rpi-2\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.103 rpi-3\" >> /etc/hosts' We can then create a file in home directory listing nodes. cat <<EOF >> ~/machinefile rpi-0 rpi-1 rpi-2 rpi-3 EOF The easiest way to run commands or code is with the mpirun command. This command, run in a shell, will launch multiple copies of your code, and set up communications between them. As each Pi has four cores and we have four we can specify number of processors to run as sixteen. mpirun -np 16 -machinefile ~/machinefile vcgencmd measure_temp While its interesting running individual commands across nodes the MPI for Python module exposes options for programs to spread load. A simple test of this is where we scatter a bunch of elements, like those in a list, to processing nodes. cat <<EOF >> ~/scatter.py from mpi4py import MPI comm = MPI.COMM_WORLD size = comm.Get_size() rank = comm.Get_rank() if rank == 0: data = [(x+1)**x for x in range(size)] print ('we will be scattering:',data) else: data = None data = comm.scatter(data, root=0) print ('rank',rank,'has data:',data) EOF Once script created execute: mpirun -np 16 -machinefile ~/machinefile python3 ~/scatter.py While scattering elements of a list is interesting splitting up a processing problem and distributing to multiple processing nodes is more fun. Calculating Pi is a nice example of this, and its nice for a Pi cluster to calculate Pi with MPI. wget -O ~/pi.py https://raw.githubusercontent.com/darrylcauldwell/piCluster/main/scripts/pi.py mpirun -np 16 -machinefile ~/machinefile python3 pi.py","title":"MPI"},{"location":"mpi/#parrallel-programming","text":"Each Raspberry Pi is a small unit of compute, one of my goals is to understand how operating many in a cluster. There are various approaches to parallel computational models, message-passing has proven to be an effective one. MPI the Message Passing Interface, is a standardized and portable message-passing system designed to function on a wide variety of parallel computers. My prefered language is Python and usefully there is MPI for Python . sudo apt-get install -y libopenmpi-dev python-dev pip sudo pip install mpi4py mpirun --version All the RPIs in the cluster will access each other via SSH, this communication needs to be passwordless. The first thing you need to do is generate an SSH key pair on first host. ssh-keygen -t rsa -b 4096 Once key generated to enable passwordless access, upload a copy of the public key to the other three servers. ssh-copy-id ubuntu@[server_ip_address] Repeat keygen and copy public key process on all four hosts. In order for mpi to distribute workload the node where execution occurs needs to understand which nodes are available. The machinename parameter can be used to point to a text file containing list of nodes. In order name we can use names we can add entries to hosts file. sudo sh -c 'echo \"192.168.1.100 rpi-0\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.101 rpi-1\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.102 rpi-2\" >> /etc/hosts' sudo sh -c 'echo \"192.168.1.103 rpi-3\" >> /etc/hosts' We can then create a file in home directory listing nodes. cat <<EOF >> ~/machinefile rpi-0 rpi-1 rpi-2 rpi-3 EOF The easiest way to run commands or code is with the mpirun command. This command, run in a shell, will launch multiple copies of your code, and set up communications between them. As each Pi has four cores and we have four we can specify number of processors to run as sixteen. mpirun -np 16 -machinefile ~/machinefile vcgencmd measure_temp While its interesting running individual commands across nodes the MPI for Python module exposes options for programs to spread load. A simple test of this is where we scatter a bunch of elements, like those in a list, to processing nodes. cat <<EOF >> ~/scatter.py from mpi4py import MPI comm = MPI.COMM_WORLD size = comm.Get_size() rank = comm.Get_rank() if rank == 0: data = [(x+1)**x for x in range(size)] print ('we will be scattering:',data) else: data = None data = comm.scatter(data, root=0) print ('rank',rank,'has data:',data) EOF Once script created execute: mpirun -np 16 -machinefile ~/machinefile python3 ~/scatter.py While scattering elements of a list is interesting splitting up a processing problem and distributing to multiple processing nodes is more fun. Calculating Pi is a nice example of this, and its nice for a Pi cluster to calculate Pi with MPI. wget -O ~/pi.py https://raw.githubusercontent.com/darrylcauldwell/piCluster/main/scripts/pi.py mpirun -np 16 -machinefile ~/machinefile python3 pi.py","title":"Parrallel Programming"},{"location":"storage/","text":"SD Card Performance Linux FIO tool will be used to measure sequential write performance of a 4GB file: fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write The tool output shows sequential read rate: IOPS=10.1k, BW=39.5MiB/s IOPS=10.1k, BW=39.3MiB/s IOPS=10.1k, BW=39.4MiB/s IOPS=10.1k, BW=39.3MiB/s Similarly, the tool will be used to measure sequential read performance of a 4GB file: fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=read The tool output shows sequential write rate: IOPS=5429, BW=21.2MiB/s IOPS=5128, BW=20.0MiB/s IOPS=5136, BW=20.1MiB/s IOPS=5245, BW=20.5MiB/s With the SD card the performance bottleneck is the reader which supports peak bandwidth 50MiB/s. To test this I has a lower spec SanDisk Ultra card so I repeated test and got near exact throughput to the SanDisk Extreme. The tool output shows sequential read rate: IOPS=10.1k, BW=39.4MiB/s The tool output shows sequential write rate: IOPS=5245, BW=20.5MiB/s USB Flash Performance The USB flash drive should deliver improved performance, first check it can be seen by the system and note its device. Then repeated the same performance tests using fio on the SSD. Linux FIO tool will be used to measure sequential write/read performance of a 4GB file: cd /mnt/ssd fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write The tool output shows sequential write rate: IOPS=14.5k, BW=56.6MiB/s IOPS=14.4k, BW=56.4MiB/s IOPS=14.4k, BW=56.2MiB/s IOPS=11.9k, BW=46.6MiB/s cd /mnt/ssd fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/ssd/test --bs=4k --iodepth=64 --size=4G --readwrite=read The tool output shows sequential read rate: IOPS=33.3k, BW=130MiB/s IOPS=37.0k, BW=148MiB/s IOPS=42.6k, BW=166MiB/s IOPS=42.5k, BW=166MiB/s So for a very small investment inpwd the USB Flash Drives we've increased sequential read potential by 4X and write potential by 3X. The Pi 4 firmware doesn't presently offer option for USB boot so the SD cards are needed but hopefully soon the firmware will get updated.","title":"Storage"},{"location":"storage/#sd-card-performance","text":"Linux FIO tool will be used to measure sequential write performance of a 4GB file: fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write The tool output shows sequential read rate: IOPS=10.1k, BW=39.5MiB/s IOPS=10.1k, BW=39.3MiB/s IOPS=10.1k, BW=39.4MiB/s IOPS=10.1k, BW=39.3MiB/s Similarly, the tool will be used to measure sequential read performance of a 4GB file: fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=read The tool output shows sequential write rate: IOPS=5429, BW=21.2MiB/s IOPS=5128, BW=20.0MiB/s IOPS=5136, BW=20.1MiB/s IOPS=5245, BW=20.5MiB/s With the SD card the performance bottleneck is the reader which supports peak bandwidth 50MiB/s. To test this I has a lower spec SanDisk Ultra card so I repeated test and got near exact throughput to the SanDisk Extreme. The tool output shows sequential read rate: IOPS=10.1k, BW=39.4MiB/s The tool output shows sequential write rate: IOPS=5245, BW=20.5MiB/s","title":"SD Card Performance"},{"location":"storage/#usb-flash-performance","text":"The USB flash drive should deliver improved performance, first check it can be seen by the system and note its device. Then repeated the same performance tests using fio on the SSD. Linux FIO tool will be used to measure sequential write/read performance of a 4GB file: cd /mnt/ssd fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write The tool output shows sequential write rate: IOPS=14.5k, BW=56.6MiB/s IOPS=14.4k, BW=56.4MiB/s IOPS=14.4k, BW=56.2MiB/s IOPS=11.9k, BW=46.6MiB/s cd /mnt/ssd fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/ssd/test --bs=4k --iodepth=64 --size=4G --readwrite=read The tool output shows sequential read rate: IOPS=33.3k, BW=130MiB/s IOPS=37.0k, BW=148MiB/s IOPS=42.6k, BW=166MiB/s IOPS=42.5k, BW=166MiB/s So for a very small investment inpwd the USB Flash Drives we've increased sequential read potential by 4X and write potential by 3X. The Pi 4 firmware doesn't presently offer option for USB boot so the SD cards are needed but hopefully soon the firmware will get updated.","title":"USB Flash Performance"},{"location":"ubuntu/","text":"Install and Configure I used Raspberry Pi imager to install the Ubuntu 20.10 64bit on each SD Card. Insert these into the Pi's and power them on. The image is configured with DHCP client, Pi device MAC addresses are prefixed DC:A6:32 . I connected to my router which acts as DHCP server and found the four leases sorting by MAC. With the DHCP addresses can connect via SSH, the Ubuntu image has default username of ubuntu and password ubuntu . You're prompted to change password at first connect. I want to reliably know how to connect to these and like to change from dynamic to a staticly asssigned IP address. To do this for Ubuntu 20.10 we update Netplan configuration. sudo vi /etc/netplan/50-cloud-init.yaml Here is example of how I update this to reflect static IP. network: ethernets: eth0: addresses: [192.168.1.100/24] gateway4: 192.168.1.254 nameservers: addresses: [8.8.8.8,8.8.4.4] dhcp4: no match: driver: bcmgenet smsc95xx lan78xx optional: true set-name: eth0 version: 2 With the configuration file updated can have netplan load the config. sudo netplan --debug apply With any new install its useful to apply latest patches. sudo apt update sudo apt upgrade -y Install Tools The VideoCore packages provide command line utilities that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. The linux flexible I/O tester tool is easy to use and useful for understanding storage sub-system performance. sudo apt install -y libraspberrypi-bin Storage Performance The linux flexible I/O tester tool is easy to use and useful for understanding storage sub-system performance. sudo apt install -y fio USB Flash Disk The SD card on the Pi will normally show as /dev/mmcblk0. The USB drive will normally show as /dev/sda. The following could be data destructive so check the enumeration before proceeding. sudo fdisk -l Then create primary partition on USB device sudo sfdisk /dev/sda << EOF ; EOF Then format and label the partition then mount and set permissions for the parition sudo mkfs.ext4 -L SSD /dev/sda1 sudo mkdir /mnt/ssd sudo mount /dev/sda1 /mnt/ssd echo \"LABEL=SSD /mnt/ssd ext4 defaults 0 2\" | sudo cat /etc/fstab - sudo chmod 777 .","title":"Ubuntu"},{"location":"ubuntu/#install-and-configure","text":"I used Raspberry Pi imager to install the Ubuntu 20.10 64bit on each SD Card. Insert these into the Pi's and power them on. The image is configured with DHCP client, Pi device MAC addresses are prefixed DC:A6:32 . I connected to my router which acts as DHCP server and found the four leases sorting by MAC. With the DHCP addresses can connect via SSH, the Ubuntu image has default username of ubuntu and password ubuntu . You're prompted to change password at first connect. I want to reliably know how to connect to these and like to change from dynamic to a staticly asssigned IP address. To do this for Ubuntu 20.10 we update Netplan configuration. sudo vi /etc/netplan/50-cloud-init.yaml Here is example of how I update this to reflect static IP. network: ethernets: eth0: addresses: [192.168.1.100/24] gateway4: 192.168.1.254 nameservers: addresses: [8.8.8.8,8.8.4.4] dhcp4: no match: driver: bcmgenet smsc95xx lan78xx optional: true set-name: eth0 version: 2 With the configuration file updated can have netplan load the config. sudo netplan --debug apply With any new install its useful to apply latest patches. sudo apt update sudo apt upgrade -y","title":"Install and Configure"},{"location":"ubuntu/#install-tools","text":"The VideoCore packages provide command line utilities that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. The linux flexible I/O tester tool is easy to use and useful for understanding storage sub-system performance. sudo apt install -y libraspberrypi-bin","title":"Install Tools"},{"location":"ubuntu/#storage-performance","text":"The linux flexible I/O tester tool is easy to use and useful for understanding storage sub-system performance. sudo apt install -y fio","title":"Storage Performance"},{"location":"ubuntu/#usb-flash-disk","text":"The SD card on the Pi will normally show as /dev/mmcblk0. The USB drive will normally show as /dev/sda. The following could be data destructive so check the enumeration before proceeding. sudo fdisk -l Then create primary partition on USB device sudo sfdisk /dev/sda << EOF ; EOF Then format and label the partition then mount and set permissions for the parition sudo mkfs.ext4 -L SSD /dev/sda1 sudo mkdir /mnt/ssd sudo mount /dev/sda1 /mnt/ssd echo \"LABEL=SSD /mnt/ssd ext4 defaults 0 2\" | sudo cat /etc/fstab - sudo chmod 777 .","title":"USB Flash Disk"}]}